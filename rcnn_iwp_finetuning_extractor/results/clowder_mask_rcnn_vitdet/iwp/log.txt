[01/31 16:41:25] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 16:41:26] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Dec  5 2024, 14:17:24) [GCC 13.3.0]
numpy                            1.26.4
detectron2                       0.6 @/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/detectron2
Compiler                         GCC 13.3
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1+cu121 @/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA A100-SXM4-80GB (arch=8.0)
Driver version                   550.127.08
CUDA_HOME                        None - invalid!
Pillow                           11.1.0
torchvision                      0.17.1+cu121 @/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torchvision
torchvision arch flags           /home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[01/31 16:41:26] detectron2 INFO: Command line arguments: {'config_file': 'configs/clowder_mask_rcnn_vitdet.py', 'resume': False, 'eval_only': False, 'num_gpus': 1, 'num_machines': 1, 'machine_rank': 0, 'dist_url': 'tcp://127.0.0.1:50815', 'opts': [], 'dataset': 'iwp', 'compute_f1': None, 'vit_freeze': True, 'model': 'clowder_mask_rcnn_vitdet'}
[01/31 16:41:26] detectron2 INFO: Full config saved to results/clowder_mask_rcnn_vitdet/iwp/config.yaml
[01/31 16:41:30] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): SimpleFeaturePyramid(
    (simfp_2): Sequential(
      (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2))
      (4): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (5): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_3): Sequential(
      (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_4): Sequential(
      (0): Conv2d(
        768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_5): Sequential(
      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): Conv2d(
        768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (net): ViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (blocks): ModuleList(
        (0-11): 12 x Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (top_block): LastLevelMaxPool()
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[01/31 16:42:25] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 16:42:26] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.11 | packaged by conda-forge | (main, Dec  5 2024, 14:17:24) [GCC 13.3.0]
numpy                            1.26.4
detectron2                       0.6 @/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/detectron2
Compiler                         GCC 13.3
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1+cu121 @/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA A100-SXM4-80GB (arch=8.0)
Driver version                   550.127.08
CUDA_HOME                        None - invalid!
Pillow                           11.1.0
torchvision                      0.17.1+cu121 @/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torchvision
torchvision arch flags           /home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.11.0
-------------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[01/31 16:42:26] detectron2 INFO: Command line arguments: {'config_file': 'configs/clowder_mask_rcnn_vitdet.py', 'resume': False, 'eval_only': False, 'num_gpus': 1, 'num_machines': 1, 'machine_rank': 0, 'dist_url': 'tcp://127.0.0.1:50815', 'opts': [], 'dataset': 'iwp', 'compute_f1': None, 'vit_freeze': True, 'model': 'clowder_mask_rcnn_vitdet'}
[01/31 16:42:26] detectron2 INFO: Full config saved to results/clowder_mask_rcnn_vitdet/iwp/config.yaml
[01/31 16:42:29] detectron2 INFO: Model:
GeneralizedRCNN(
  (backbone): SimpleFeaturePyramid(
    (simfp_2): Sequential(
      (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2))
      (4): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (5): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_3): Sequential(
      (0): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2))
      (1): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_4): Sequential(
      (0): Conv2d(
        768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (simfp_5): Sequential(
      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): Conv2d(
        768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): LayerNorm()
      )
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
      )
    )
    (net): ViT(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (blocks): ModuleList(
        (0-11): 12 x Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (top_block): LastLevelMaxPool()
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (conv4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): LayerNorm()
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[01/31 16:42:30] d2.data.datasets.coco INFO: Loaded 201 images in COCO format from data/iwp/iwp_train.json
[01/31 16:42:30] d2.data.build INFO: Removed 0 images with no usable annotations. 201 images left.
[01/31 16:42:30] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    iwp     | 4418         |
|            |              |[0m
[01/31 16:42:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/31 16:42:30] d2.data.common INFO: Serializing 201 elements to byte tensors and concatenating them all ...
[01/31 16:42:30] d2.data.common INFO: Serialized dataset takes 0.54 MiB
[01/31 16:42:30] d2.data.build INFO: Making batched data loader with batch_size=1
[01/31 16:42:30] d2.data.datasets.coco INFO: Loaded 67 images in COCO format from data/iwp/iwp_val.json
[01/31 16:42:30] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    iwp     | 1466         |
|            |              |[0m
[01/31 16:42:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/31 16:42:30] d2.data.common INFO: Serializing 67 elements to byte tensors and concatenating them all ...
[01/31 16:42:30] d2.data.common INFO: Serialized dataset takes 0.18 MiB
[01/31 16:42:30] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_base.pth?matching_heuristics=True ...
[01/31 16:42:30] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/mohanar2/.torch/iopath_cache/detectron2/ImageNetPretrained/MAE/mae_pretrain_vit_base.pth ...
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_2.4.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_2.4.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_2.5.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_2.5.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_3.1.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_3.1.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_3.2.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_3.2.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_4.0.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_4.0.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_4.1.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_4.1.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_5.1.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_5.1.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of backbone.simfp_5.2.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of backbone.simfp_5.2.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv1.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv1.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv2.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv2.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv3.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv3.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv4.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.box_head.conv4.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn1.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn1.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn2.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn2.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn3.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn3.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.bias in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn4.norm.bias in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.bias will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: Shape of norm.weight in checkpoint is torch.Size([768]), while shape of roi_heads.mask_head.mask_fcn4.norm.weight in model is torch.Size([256]).
[01/31 16:42:31] d2.checkpoint.c2_model_loading WARNING: norm.weight will not be loaded. Please double check and see if this is desired.
[01/31 16:42:31] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.net - Total num: 74
[01/31 16:42:31] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.simfp_2.0.{bias, weight}[0m
[34mbackbone.simfp_2.1.{bias, weight}[0m
[34mbackbone.simfp_2.3.{bias, weight}[0m
[34mbackbone.simfp_2.4.norm.{bias, weight}[0m
[34mbackbone.simfp_2.4.weight[0m
[34mbackbone.simfp_2.5.norm.{bias, weight}[0m
[34mbackbone.simfp_2.5.weight[0m
[34mbackbone.simfp_3.0.{bias, weight}[0m
[34mbackbone.simfp_3.1.norm.{bias, weight}[0m
[34mbackbone.simfp_3.1.weight[0m
[34mbackbone.simfp_3.2.norm.{bias, weight}[0m
[34mbackbone.simfp_3.2.weight[0m
[34mbackbone.simfp_4.0.norm.{bias, weight}[0m
[34mbackbone.simfp_4.0.weight[0m
[34mbackbone.simfp_4.1.norm.{bias, weight}[0m
[34mbackbone.simfp_4.1.weight[0m
[34mbackbone.simfp_5.1.norm.{bias, weight}[0m
[34mbackbone.simfp_5.1.weight[0m
[34mbackbone.simfp_5.2.norm.{bias, weight}[0m
[34mbackbone.simfp_5.2.weight[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv0.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.conv1.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.conv1.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv1.weight[0m
[34mroi_heads.box_head.conv2.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv2.weight[0m
[34mroi_heads.box_head.conv3.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv3.weight[0m
[34mroi_heads.box_head.conv4.norm.{bias, weight}[0m
[34mroi_heads.box_head.conv4.weight[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.weight[0m
[34mroi_heads.mask_head.mask_fcn2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.weight[0m
[34mroi_heads.mask_head.mask_fcn3.norm.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.weight[0m
[34mroi_heads.mask_head.mask_fcn4.norm.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.weight[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[01/31 16:42:31] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mcls_token[0m
  [35mnorm.{bias, weight}[0m
[01/31 16:42:31] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 16:42:32] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/detectron2/engine/train_loop.py", line 155, in train
    self.run_step()
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/detectron2/engine/train_loop.py", line 494, in run_step
    loss_dict = self.model(data)
                ^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/pdg-extractors/rcnn_iwp_finetuning_extractor/models/rcnn.py", line 151, in forward
    features = self._compute_features(images, batched_inputs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/pdg-extractors/rcnn_iwp_finetuning_extractor/models/rcnn.py", line 253, in _compute_features
    return self.backbone(images.tensor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/pdg-extractors/rcnn_iwp_finetuning_extractor/models/simple_feature_pyramid.py", line 183, in forward
    bottom_up_features = self.net(x)
                         ^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/detectron2/modeling/backbone/vit.py", line 357, in forward
    x = blk(x)
        ^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/detectron2/modeling/backbone/vit.py", line 218, in forward
    x = self.attn(x)
        ^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mohanar2/.conda/envs/hf-extractors/lib/python3.11/site-packages/detectron2/modeling/backbone/vit.py", line 77, in forward
    attn = attn.softmax(dim=-1)
           ^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 18.81 MiB is free. Process 140157 has 77.69 GiB memory in use. Including non-PyTorch memory, this process has 1.40 GiB memory in use. Of the allocated memory 869.07 MiB is allocated by PyTorch, and 52.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[01/31 16:42:32] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[01/31 16:42:32] d2.utils.events INFO:  iter: 0       lr: N/A  max_mem: 875M
